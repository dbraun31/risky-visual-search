---
title: 'Prospect Theory Modeling Tests'
author: 'Dave Braun'
date: January 12, 2023
output:
    md_document:
        variant: markdown_github
        toc: TRUE
        df_print: 'paged'
        standalone: TRUE
knit: (function(input, encoding, output) {knitr::knit(input=input, encoding = encoding, output='../md/prospect-theory-modeling-tests.md')})
---

```{r include = FALSE, setup}
## super useful docs on knitr
## https://yihui.org/knitr/options/#chunk_options

knitr::opts_knit$set(base.dir = '/home/dave/Dropbox (Lehigh University)/post_doc/professional/projects/gaita/ideation/structured/md/')
#knitr::opts_knit(base.dir = paste0(getwd(), '/../md/'))
knitr::opts_chunk$set(fig.path = 'figures/', 
                      fig.align = 'center',
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE)

options(mc.cores = parallel::detectCores())
```

```{r include = FALSE}
library(tidyverse)
library(latex2exp)
library(BH)
library(rstan)
library(gridExtra)
```

# Prospect Theory Modeling Tests

## Simulate data

I'm going to do a pretty simple simulation with a small set of parameters (not nested within subjects or anything), with the usual value function (maybe constraining $\alpha = \beta$) and a greatly simplified probability weighting function.

Overall value for a prospect with two outcomes updated to include a cost function instead of value function:

$$
V = \Sigma~\pi(p)\cdot -Cost(x)
$$

Cost function

$$
Cost(x) = \begin{cases}
-(x)^{\alpha} & \text{if } x \geq 0 \\
\lambda(-x)^{\beta} & \text{if } x < 0
\end{cases}
$$

The scale of $x$ here gets a bit tricky. If I'm manipulating effort demand as a response time window, then effort demand decreases as the response window increases. I think my approach will be to flip the sign of $x$ in the function, which is a bit confusing. But I think it's more important to have the range of the cost function scale with some aversive quantity, rather than just flipping it into a value function. And of course, in keeping with prospect theory, $x$ is coded relative to a reference point.

$x$ reflects the response time window, which is inversely related to objective effort demand and therefore subjective effort cost. That is to say, as there is more time to response, the task becomes less effortful. So, in keeping with mainstream views in the literature, the subjective sense of effort cost $Cost(x)$ scales as a positive, monotonic function of effort demand, which is the inverse of the response time window $-x$. And for simplicity, $\alpha = \beta$. And $\alpha > 1$ to reflect increasing sensitivity in the context of experienced costs.

I'll plot this to make it more clear:

```{r plot-value-function}
cost <- function(x, alpha = 2.5, lambda = 2){
   if (x >= 0) {
       return(-(x)^alpha)
   } 
    return(lambda * (-x)^alpha)
}

d <- data.frame(x = seq(-1, 1, by = .001))
d$cost <- sapply(d$x, FUN = cost)

d %>% 
    ggplot(aes(x = -x, y = cost)) + 
    geom_hline(yintercept = 0) + 
    geom_vline(xintercept = 0) + 
    geom_line(size = 1.5) + 
    annotate('text', x = -.8, y = 0.5, label = 'Less effort demand') + 
    annotate('text', x = .8, y = 0.5, label = 'More effort demand') + 
    annotate('text', x = -.7, y = -1.85, label = 'Increased response time window') + 
    annotate('text', x = .7, y = -1.85, label = 'Reduced response time window') + 
    labs(
        x = 'Inverse Response Time Window',
        y = 'Cost'
    ) + 
    ylim(-2,2) + 
    theme_bw() + 
    theme(axis.text = element_blank(),
          axis.ticks = element_blank(),
          panel.grid = element_blank())
```


Probability weighting function, modified for simplicity


$$
\begin{align*}
\pi(p) = \begin{cases}
p \cdot \gamma & \text{if } p = 0.5\\
1 & \text{if } p = 1
\end{cases}\\
\gamma \in (0, 1)\\
p \in \{0.5, 1\}
\end{align*}
$$

Logistic choice rule


$$
p(safe) = \frac{1}{1 + e^{\varphi[V(risky) - V(safe)]}}
$$

Where when $\varphi=0;~p(safe)=0.5$ and the choice becomes more
deterministically in line with subjective value as $\varphi$ approaches $1$.

So the full set of parameters is $\{\alpha, \lambda, \gamma, \varphi\}$.

Some fixed values:


$$
\begin{align*}
\alpha = 1.5^*\\
\lambda = 2\\
\gamma = 0.7\\
\varphi = 0.8
\end{align*}
$$

\* *$\alpha>1$ reflects increasing sensitivity prediction.*

### Run simulation

Let's assume the response time window is manipulated discretely, and standardized relative to individual subjects so it'll be on the scale of quantile. So let's define the space of possible prospects as ($(outcome_1, probability_1; \ldots;~outcome_n, probability_n)$):


$$
\begin{align*}
\text{Moderate gain: }[(0, 0.5; 0.5, 0.5), (0.25, 1)]\\
\text{Moderate loss: }[(0, 0.5; -0.5, 0.5), (-0.25, 1)]\\
\text{Extreme gain: }[(0, 0.5; 1, 0.5), (0.5, 1)]\\
\text{Extreme loss: }[(0, 0.5; -1, 0.5), (-0.5, 1)]\\
\end{align*}
$$


```{r}
data <- data.frame(risky1 = seq(-1, 1, by = 0.5), 
                   risky2 = c(-0.5, 0, 0, 0, 0.5),
                   safe = c(-.75, -.25, 0, .25, .75))
data <- data[data$risky1 != 0,]
data <- do.call('rbind', replicate(1000, data, simplify = FALSE))

## parameters
alpha = 3
lambda = 2
## from tversky kahneman 1992
gamma = .877
phi = .4


## functions
p_choose_safe <- function(Vrisky, Vsafe) {
    return(1 / (1 + exp(phi * (Vrisky - Vsafe))))
}

V <- function(x, p) {
    out <- 0
    for (outcome in x) {
        out <- out + (pweight(p, gamma = gamma) * value(outcome, alpha = alpha, lambda = lambda)) 
    }
    return(out)
}

value <- function(x, alpha, lambda) {
    if (x >= 0) {
        return(x^alpha)
    } 
    return(-lambda * (-x)^alpha)
}

cost <- function(x, alpha, lambda){
   if (x >= 0) {
       return(-(x)^alpha)
   } 
    return(lambda * (-x)^alpha)
}


pweight <- function(p, gamma, neutralize = TRUE) {
    # adjusting to neutralize function
    if (neutralize) {
        return(p)
    }
    
    if (p == 1){
        return(1)
    }
    return(p * gamma)
}

choose <- function(risky1, risky2, safe, mul = 2) {
    Vrisky <- V(x = c(risky1, risky2)*mul, p = 0.5)
    Vsafe <- V(x = safe*mul, p = 1)
    return(p_choose_safe(Vrisky, Vsafe))
}

data$ssd_p <- mapply(choose, data$risky1, data$risky2, data$safe)
data$ssd <- rbinom(nrow(data), 1, data$ssd_p)
data %>% 
    mutate(framing = ifelse(risky1 > 0, 'Easier', 'Harder')) %>% 
    ggplot(aes(x = framing, y = ssd)) + 
    geom_jitter(alpha = .4, height = .05) + 
    #geom_bar(stat = 'summary', fun.y = 'mean', fill = 'steelblue', alpha = .6) + 
    stat_summary(fun = 'mean', geom='bar', fill = 'steelblue', alpha = .6) + 
    #geom_errorbar(stat = 'summary', fun.y = 'sd', width = .5) + 
    labs(
        x = 'Framing', 
        y = 'Proportion Selection Safe Deck'
    ) + 
    theme_bw() + 
    theme(axis.ticks = element_blank(),
          panel.grid = element_blank())
```
 


If I'm not missing anything obvious, these tests are pointing to the idea that probability of choice is *strongly* influenced by the absolute levels of $x$. The ordinal predictions aren't, but the effect size totally is...

So the only thing I can think of is if the scale of the decision sensitivity parameter just scales proportionately with the scale of the objective outcomes, and maybe the other parameters are invariant? Because preference strength still depends on absolute level even when controlling for absolute differences in absolute outcomes. So I'm not sure. This would be a good thing to test during parameter recovery.

Another interesting thing to keep an eye on is what level alpha will need to be to offset the influence of the probability weighting function discounting probability.

## Modeling

```{stan output.var = 'prospect_model', eval = FALSE}
// this model does well
data {
    int N;
    real risky1[N];
    real risky2[N];
    real safe[N];
    int choice[N];
}

parameters {
    real<lower=0, upper=10> lambda;
    real<lower=0, upper=5> alpha;
    real<lower=0, upper=1> gamma;
    real<lower=0, upper=15> phi;
}

model {
    real sv[N];
    real risky1v[N];
    real risky2v[N];
    real safev[N];
    
    // priors
    lambda ~ uniform(0, 4);
    alpha ~ uniform(0, 4);
    gamma ~ uniform(0, 1);
    phi ~ uniform(0, 12);
    
    for (i in 1:N) {
        if (risky1[i] < 0) {
            risky1v[i] = -lambda * (-risky1[i])^alpha * (0.5*gamma);
            risky2v[i] = -lambda * (-risky2[i])^alpha * (0.5*gamma);
            safev[i] = -lambda * (-safe[i])^alpha;
        } else {
            risky1v[i] = (risky1[i])^alpha * (0.5*gamma);
            risky2v[i] = (risky2[i])^alpha * (0.5*gamma);
            safev[i] = (safe[i])^alpha;
        }
        sv[i] = inv_logit(phi * ((risky1v[i] + risky2v[i]) - safev[i]));
    }
    choice ~ bernoulli(sv);
}
```

```{stan output.var = 'prospect_model'}
// less informative priors and no probability weighting
data {
    int N;
    real risky1[N];
    real risky2[N];
    real safe[N];
    int choice[N];
}

parameters {
    real<lower=0, upper=10> lambda;
    real<lower=0, upper=10> alpha;
    real<lower=0, upper=10> phi;
}

model {
    real sv[N];
    real risky1v;
    real risky2v;
    real safev;
    
    // priors
    lambda ~ uniform(0, 10);
    alpha ~ uniform(0, 10);
    phi ~ uniform(0, 2);
    
    for (i in 1:N) {
        if (risky1[i] < 0) {
            risky1v = -lambda * ((-risky1[i])^alpha) * 0.5;
            risky2v = -lambda * ((-risky2[i])^alpha) * 0.5;
            safev = -lambda * (-safe[i])^alpha;
        } else {
            risky1v = (risky1[i]^alpha) * 0.5;
            risky2v = (risky2[i]^alpha) * 0.5;
            safev = (safe[i]^alpha);
        }
        sv[i] = 1 / (1 + exp(-phi * (safev - (risky1v + risky2v))));
    }
    choice ~ bernoulli(sv);
}
```



```{r}

fit <- sampling(prospect_model,
            data = list(N = nrow(data),
                        risky1 = data$risky1,
                        risky2 = data$risky2,
                        safe = data$safe,
                        choice = data$ssd),
            warmup = 750,
            iter = 2000,
            chains = 3)

```
```{r}
print(fit)
```
```{r}
result <- as.data.frame(fit)
result$iteration <- 1:(nrow(result))
result <- result %>% 
    select(-lp__) %>% 
    gather(parameter, estimate, lambda:phi)
```


```{r}
params <- c(
    alpha = alpha,
    lambda = lambda,
    phi = phi
)
params <- data.frame(parameter = names(params), ground_truth = params)
params <- result %>% 
    group_by(parameter) %>% 
    summarize(mean = mean(estimate), lower = quantile(estimate, probs = .025),
              upper = quantile(estimate, probs = .975), sd = sd(estimate)) %>% 
    inner_join(params)

result %>% 
    ggplot(aes(x = iteration, y = estimate)) + 
    geom_line(alpha = .6) + 
    geom_hline(data = params, aes(yintercept = ground_truth), 
               linetype = 'dashed', color = 'steelblue', size = 2) +
    facet_wrap(~parameter, scales = 'free') + 
    theme_bw() + 
    theme(axis.ticks = element_blank(),
          panel.grid = element_blank(),
          strip.background = element_rect(color = 'black', fill = 'white'))

result %>% 
    ggplot(aes(x = estimate)) + 
    geom_histogram(fill = 'steelblue', alpha = .6) + 
    geom_vline(data = params, aes(xintercept = mean), linetype = 'dashed', color = 'yellow') + 
    geom_vline(data = params, aes(xintercept = lower), linetype = 'dashed', color = 'yellow') + 
    geom_vline(data = params, aes(xintercept = upper), linetype = 'dashed', color = 'yellow') + 
    geom_vline(data = params, aes(xintercept = ground_truth), linetype = 'dashed', color = 'green') +
    labs(
        x = 'Estimate',
        y = 'Count'
    ) + 
    facet_wrap(~parameter, scales = 'free') +
    theme_bw() + 
    theme(strip.background = element_rect(color = 'black', fill = 'white'))
```


Estimation of $\gamma$ needs to be constrained in the range $[0, 1]$ in order for the model to perform well.

I need to look really carefully at how the likelihood function is being defined.
These posterior distributions are stable but mostly reliably missing the true
parameter values.


Realized my wonky cost function coding was making things backwards.










