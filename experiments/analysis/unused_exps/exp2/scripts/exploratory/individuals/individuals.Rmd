---
title: 'Risky Visual Search - Experiment 2 Individual Differences Analysis'
author: 'Dave Braun'
date: '`r format(Sys.time(), "%b %d %Y, %H:%M:%S")`'
output:
  html_document:
    theme: flatly
    code_folding: hide
    df_print: paged
    toc: true
    includes:
      after_body: ../../../../html/footer.html
      in_header: ../../../../html/favicon.html
knit:
  (function(inputFile, encoding) {
    rmarkdown::render(inputFile,
    encoding = encoding,
    output_file = 'index.html')})
---


This document was last updated at `r Sys.time()`.

```{r include = FALSE}
library(tidyverse)
library(ggExtra)
library(plotly)
```


```{r}
exp <- str_extract(getwd(), 'exp\\d[a-z]?')
d <- read.csv(paste0(here::here(), '/experiments/analysis/', exp, '/data/', exp, '_main_full.csv'))
demo <- read.csv(paste0(here::here(), '/experiments/analysis/', exp, '/data/', exp, '_demo.csv'))
N <- length(unique(d$subject))
head(d)
```

Initial sample size is `r N`.

**Preprocess NFC scale**

```{r}
reverse_items <- c(3,4,5,7,8,9,12,16,17)
response_code <- data.frame(response = c('neutral', 'somewhat_agree', 'somewhat_disagree', 'strongly_agree', 'strongly_disagree', ''), numeric = c(3, 4, 2, 5, 1, NA))
survey <- demo %>% 
  gather(question, response, cog_effort_q1:cog_effort_q18) %>% 
  select(subject, question, response) %>% 
  inner_join(response_code) 

parse_question <- function(q) {
  return(as.numeric(sub('.', '', unlist(strsplit(q, split='_'))[3])))
}

survey <- survey %>% 
  mutate(question = Vectorize(parse_question)(question)) %>% 
  mutate(numeric_final = ifelse(question %in% reverse_items, 6-numeric, numeric)) %>% 
  arrange(subject) %>% 
  select(-response, -numeric) %>% 
  rename(response = numeric_final) 

survey %>% 
  filter(!is.na(response)) %>% 
  group_by(subject) %>% 
  summarize(cog_need = mean(response)) %>% 
  ggplot(aes(x = cog_need)) + 
  geom_histogram(color = 'black')
  
survey %>% 
  group_by(subject) %>% 
  summarize(missing = sum(is.na(response)) / nrow(.)) %>% 
  ggplot(aes(x = missing)) + 
  geom_histogram(color = 'black') + 
  labs(
    x = 'Proportion Survey Unanswered',
    y = 'Frequency'
  )

cog_need <- survey %>% 
  filter(!is.na(response)) %>% 
  group_by(subject) %>% 
  summarize(cog_need_score = mean(response))
  
```

```{r}
## merge cog need with overall data
d <- d %>% 
  inner_join(cog_need)  
```
```{r}
## look at it

cor_data <- d %>% 
  group_by(subject, direction) %>% 
  summarize(ssd = mean(ssd)) %>% 
  spread(direction, ssd) %>% 
  mutate(effect = `Harder than Reference` - `Easier than Reference`) %>% 
  inner_join(d) %>% 
  group_by(subject) %>% 
  summarize(effect = unique(effect), cog_need_score = unique(cog_need_score)) 

p <- cor_data %>% 
  ggplot(aes(x = cog_need_score, y = effect)) + 
  geom_point() + 
  geom_smooth(method = 'lm') + 
  labs(
    x = 'Need for Cognition',
    y = 'Extent Aligned with Prediction'
  ) + 
  theme_bw()
  
ggMarginal(p, type = 'histogram') 
  
```

```{r}
cor.test(cor_data$effect, cor_data$cog_need_score)
```


ðŸ˜­


**Proper modeling approach**
```{r}
d$cog_need_score_sc <- scale(d$cog_need_score)[,1]

m1 <- glm(ssd ~ direction * cog_need_score_sc, data = d, family = binomial(link = 'logit'))
print('OVERALL')
summary(m1)
exp(m1$coefficients)
exp(confint(m1))


## follow ups
## high
d$cog_need_score_sc_high <- d$cog_need_score_sc - 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_high, data = d, family = binomial(link = 'logit'))
print('CENTER HIGH')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))

## low
d$cog_need_score_sc_low <- d$cog_need_score_sc + 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_low, data = d, family = binomial(link = 'logit'))
print('CENTER LOW')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
```

```{r}
test_data <- expand.grid(direction = c('Harder than Reference', 'Easier than Reference'), cog_need_score_sc = c(-1,1))
out <- predict(m1, newdata = test_data, type = 'response', se.fit = TRUE)
test_data$proba <- out$fit
test_data$se <- out$se.fit

test_data %>% 
  mutate(cog_need_score_sc = as.factor(cog_need_score_sc),
         cog_need_score_sc = recode(cog_need_score_sc, `-1` = 'One Standard Deviation Below', `1` = 'One Standard Deviation Above')) %>%  
  ggplot(aes(x = direction, y = proba, group = cog_need_score_sc)) + 
  geom_hline(yintercept = .5, linetype = 'dashed', alpha = .6) +
  geom_bar(stat = 'identity', aes(fill = cog_need_score_sc), position = position_dodge(width = .9)) + 
  geom_errorbar(aes(ymin = proba - se, ymax = proba + se), position = position_dodge(width = .9), width = .5) + 
  ylim(0,1) + 
  labs(
    x = 'Direction',
    y = 'Probability Selecting Safe Deck',
    fill = 'Need for Cognition'
  ) + 
  theme_bw() + 
  theme(legend.position = 'bottom')

```

ðŸ˜±

## Participation lag

Does the number of days the participant waited to complete the study after being assigned (as like a proxy of conscientiousness) predict their choice?



```{r}
lag <- read.csv('../../../../participation_lag.csv')
avg_lag <- mean(lag$lag_days)
lag %>% 
  ggplot(aes(x = lag_days)) + 
  geom_histogram(color = 'black', bins = 20) + 
  geom_vline(xintercept = avg_lag, linetype = 'dashed')
```


Does it correlate with need for cognition?

```{r}
## join
## losing three Ps from my og data for some reason
d <- d %>% 
  inner_join(lag, by = c('sona_id' = 'survey_id')) 
```

```{r}
cor_data <- d %>% 
  group_by(subject) %>% 
  summarize(cog_need_score = unique(cog_need_score), lag_days = unique(lag_days))
cor_data %>% 
  ggplot(aes(x = cog_need_score, lag_days)) + 
  geom_point() + 
  geom_smooth(method = 'lm')
```
```{r}
cor.test(cor_data$cog_need_score, cor_data$lag_days)
```



```{r}

  

cor_data <- d %>% 
  group_by(subject, direction) %>% 
  summarize(ssd = mean(ssd), sona_id = unique(sona_id)) %>% 
  spread(direction, ssd) %>% 
  mutate(effect = `Harder than Reference` - `Easier than Reference`) %>% 
  select(subject, sona_id, effect) %>% 
  inner_join(lag, by = c('sona_id' = 'survey_id')) 
cor_data %>% 
  ggplot(aes(x = lag_days, y = effect)) + 
  geom_point() + 
  geom_smooth(method = 'lm')
  
```





```{r}
cor.test(cor_data$effect, cor_data$lag_days)
```

**Analyze this the proper way**


```{r}
d$lag_days_sc  <- scale(d$lag_days)[,1]
d$direction_effect <- ifelse(d$direction=='Easier than Reference', -.5, .5)
m2 <- glm(ssd ~ direction_effect * lag_days_sc, data = d, family = binomial(link = 'logit'))
summary(m2)
exp(m2$coefficients)
exp(confint(m2))
```


peek at a three-way
```{r}
m3 <- glm(ssd ~ direction_effect * lag_days_sc * cog_need_score_sc, data = d, family = binomial(link = 'logit'))
summary(m3)
exp(m3$coefficients)
exp(confint(m3))
```



```{r}
library(lme4)

#mm1 <- glmer(ssd ~ direction * cog_need_score_sc + (1 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
mm1a <- glmer(ssd ~ direction * cog_need_score_sc + (1 | subject) + (0 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
mm1b <- glmer(ssd ~ direction + cog_need_score_sc + (1 | subject) + (0 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
anova(mm1a, mm1b)
#summary(mm1a)
#confint(mm1a, method = 'Wald')
```

```{r}
summary(mm1a)
exp(fixef(mm1a))
exp(confint(mm1a, method = 'Wald'))
```


















