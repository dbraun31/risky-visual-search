ggMarginal(p, type = 'histogram')
cor.test(cor_data$effect, cor_data$cog_need_score)
d$cog_need_score_sc <- scale(d$cog_need_score)[,1]
m1 <- glm(ssd ~ direction * cog_need_score_sc, data = d, family = binomial(link = 'logit'))
print('OVERALL')
summary(m1)
exp(m1$coefficients)
exp(confint(m1))
## follow ups
## high
d$cog_need_score_sc_high <- d$cog_need_score_sc - 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_high, data = d, family = binomial(link = 'logit'))
print('CENTER HIGH')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
## low
d$cog_need_score_sc_low <- d$cog_need_score_sc + 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_low, data = d, family = binomial(link = 'logit'))
print('CENTER LOW')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
test_data <- expand.grid(direction = c('Harder than Reference', 'Easier than Reference'), cog_need_score_sc = c(-1,1))
out <- predict(m1, newdata = test_data, type = 'response', se.fit = TRUE)
test_data$proba <- out$fit
test_data$se <- out$se.fit
test_data %>%
mutate(cog_need_score_sc = as.factor(cog_need_score_sc),
cog_need_score_sc = recode(cog_need_score_sc, `-1` = 'One Standard Deviation Below', `1` = 'One Standard Deviation Above')) %>%
ggplot(aes(x = direction, y = proba, group = cog_need_score_sc)) +
geom_hline(yintercept = .5, linetype = 'dashed', alpha = .6) +
geom_bar(stat = 'identity', aes(fill = cog_need_score_sc), position = position_dodge(width = .9)) +
geom_errorbar(aes(ymin = proba - se, ymax = proba + se), position = position_dodge(width = .9), width = .5) +
ylim(0,1) +
labs(
x = 'Direction',
y = 'Probability Selecting Safe Deck',
fill = 'Need for Cognition'
) +
theme_bw() +
theme(legend.position = 'bottom')
lag <- read.csv('../../../../participation_lag.csv')
avg_lag <- mean(lag$lag_days)
lag %>%
ggplot(aes(x = lag_days)) +
geom_histogram(color = 'black', bins = 20) +
geom_vline(xintercept = avg_lag, linetype = 'dashed')
## join
## losing three Ps from my og data for some reason
d <- d %>%
inner_join(lag, by = c('sona_id' = 'survey_id'))
cor_data <- d %>%
group_by(subject, direction) %>%
summarize(ssd = mean(ssd), sona_id = unique(sona_id)) %>%
spread(direction, ssd) %>%
mutate(effect = `Harder than Reference` - `Easier than Reference`) %>%
select(subject, sona_id, effect) %>%
inner_join(lag, by = c('sona_id' = 'survey_id'))
cor_data %>%
ggplot(aes(x = lag_days, y = effect)) +
geom_point() +
geom_smooth(method = 'lm')
library(tidyverse)
library(ggExtra)
library(plotly)
exp <- str_extract(getwd(), 'exp\\d[a-z]?')
d <- read.csv(paste0(here::here(), '/experiments/analysis/', exp, '/data/', exp, '_main_full.csv'))
demo <- read.csv(paste0(here::here(), '/experiments/analysis/', exp, '/data/', exp, '_demo.csv'))
N <- length(unique(d$subject))
head(d)
reverse_items <- c(3,4,5,7,8,9,12,16,17)
response_code <- data.frame(response = c('neutral', 'somewhat_agree', 'somewhat_disagree', 'strongly_agree', 'strongly_disagree', ''), numeric = c(3, 4, 2, 5, 1, NA))
survey <- demo %>%
gather(question, response, cog_effort_q1:cog_effort_q18) %>%
select(subject, question, response) %>%
inner_join(response_code)
parse_question <- function(q) {
return(as.numeric(sub('.', '', unlist(strsplit(q, split='_'))[3])))
}
survey <- survey %>%
mutate(question = Vectorize(parse_question)(question)) %>%
mutate(numeric_final = ifelse(question %in% reverse_items, 6-numeric, numeric)) %>%
arrange(subject) %>%
select(-response, -numeric) %>%
rename(response = numeric_final)
survey %>%
filter(!is.na(response)) %>%
group_by(subject) %>%
summarize(cog_need = mean(response)) %>%
ggplot(aes(x = cog_need)) +
geom_histogram(color = 'black')
survey %>%
group_by(subject) %>%
summarize(missing = sum(is.na(response)) / nrow(.)) %>%
ggplot(aes(x = missing)) +
geom_histogram(color = 'black') +
labs(
x = 'Proportion Survey Unanswered',
y = 'Frequency'
)
cog_need <- survey %>%
filter(!is.na(response)) %>%
group_by(subject) %>%
summarize(cog_need_score = mean(response))
## merge cog need with overall data
d <- d %>%
inner_join(cog_need)
## look at it
cor_data <- d %>%
group_by(subject, direction) %>%
summarize(ssd = mean(ssd)) %>%
spread(direction, ssd) %>%
mutate(effect = `Harder than Reference` - `Easier than Reference`) %>%
inner_join(d) %>%
group_by(subject) %>%
summarize(effect = unique(effect), cog_need_score = unique(cog_need_score))
p <- cor_data %>%
ggplot(aes(x = cog_need_score, y = effect)) +
geom_point() +
geom_smooth(method = 'lm') +
labs(
x = 'Need for Cognition',
y = 'Extent Aligned with Prediction'
) +
theme_bw()
ggMarginal(p, type = 'histogram')
cor.test(cor_data$effect, cor_data$cog_need_score)
d$cog_need_score_sc <- scale(d$cog_need_score)[,1]
m1 <- glm(ssd ~ direction * cog_need_score_sc, data = d, family = binomial(link = 'logit'))
print('OVERALL')
summary(m1)
exp(m1$coefficients)
exp(confint(m1))
## follow ups
## high
d$cog_need_score_sc_high <- d$cog_need_score_sc - 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_high, data = d, family = binomial(link = 'logit'))
print('CENTER HIGH')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
## low
d$cog_need_score_sc_low <- d$cog_need_score_sc + 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_low, data = d, family = binomial(link = 'logit'))
print('CENTER LOW')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
test_data <- expand.grid(direction = c('Harder than Reference', 'Easier than Reference'), cog_need_score_sc = c(-1,1))
out <- predict(m1, newdata = test_data, type = 'response', se.fit = TRUE)
test_data$proba <- out$fit
test_data$se <- out$se.fit
test_data %>%
mutate(cog_need_score_sc = as.factor(cog_need_score_sc),
cog_need_score_sc = recode(cog_need_score_sc, `-1` = 'One Standard Deviation Below', `1` = 'One Standard Deviation Above')) %>%
ggplot(aes(x = direction, y = proba, group = cog_need_score_sc)) +
geom_hline(yintercept = .5, linetype = 'dashed', alpha = .6) +
geom_bar(stat = 'identity', aes(fill = cog_need_score_sc), position = position_dodge(width = .9)) +
geom_errorbar(aes(ymin = proba - se, ymax = proba + se), position = position_dodge(width = .9), width = .5) +
ylim(0,1) +
labs(
x = 'Direction',
y = 'Probability Selecting Safe Deck',
fill = 'Need for Cognition'
) +
theme_bw() +
theme(legend.position = 'bottom')
lag <- read.csv('../../../../participation_lag.csv')
avg_lag <- mean(lag$lag_days)
lag %>%
ggplot(aes(x = lag_days)) +
geom_histogram(color = 'black', bins = 20) +
geom_vline(xintercept = avg_lag, linetype = 'dashed')
## join
## losing three Ps from my og data for some reason
d <- d %>%
inner_join(lag, by = c('sona_id' = 'survey_id'))
cor_data <- d %>%
group_by(subject, direction) %>%
summarize(ssd = mean(ssd), sona_id = unique(sona_id)) %>%
spread(direction, ssd) %>%
mutate(effect = `Harder than Reference` - `Easier than Reference`) %>%
select(subject, sona_id, effect) %>%
inner_join(lag, by = c('sona_id' = 'survey_id'))
cor_data %>%
ggplot(aes(x = lag_days, y = effect)) +
geom_point() +
geom_smooth(method = 'lm')
cor.test(cor_data$effect, cor_data$lag_days)
d$lag_days_sc  <- scale(d$lag_days)[,1]
d$direction_effect <- ifelse(d$direction=='Easier than Reference', -.5, .5)
m2 <- glm(ssd ~ direction_effect * lag_days_sc, data = d, family = binomial(link = 'logit'))
summary(m2)
exp(m2$coefficients)
exp(confint(m2))
m3 <- glm(ssd ~ direction_effect * lag_days_sc * cog_need_score_sc, data = d, family = binomial(link = 'logit'))
summary(m3)
exp(m3$coefficients)
exp(confint(m3))
library(tidyverse)
library(ggExtra)
library(plotly)
exp <- str_extract(getwd(), 'exp\\d[a-z]?')
d <- read.csv(paste0(here::here(), '/experiments/analysis/', exp, '/data/', exp, '_main_full.csv'))
demo <- read.csv(paste0(here::here(), '/experiments/analysis/', exp, '/data/', exp, '_demo.csv'))
N <- length(unique(d$subject))
head(d)
reverse_items <- c(3,4,5,7,8,9,12,16,17)
response_code <- data.frame(response = c('neutral', 'somewhat_agree', 'somewhat_disagree', 'strongly_agree', 'strongly_disagree', ''), numeric = c(3, 4, 2, 5, 1, NA))
survey <- demo %>%
gather(question, response, cog_effort_q1:cog_effort_q18) %>%
select(subject, question, response) %>%
inner_join(response_code)
parse_question <- function(q) {
return(as.numeric(sub('.', '', unlist(strsplit(q, split='_'))[3])))
}
survey <- survey %>%
mutate(question = Vectorize(parse_question)(question)) %>%
mutate(numeric_final = ifelse(question %in% reverse_items, 6-numeric, numeric)) %>%
arrange(subject) %>%
select(-response, -numeric) %>%
rename(response = numeric_final)
survey %>%
filter(!is.na(response)) %>%
group_by(subject) %>%
summarize(cog_need = mean(response)) %>%
ggplot(aes(x = cog_need)) +
geom_histogram(color = 'black')
survey %>%
group_by(subject) %>%
summarize(missing = sum(is.na(response)) / nrow(.)) %>%
ggplot(aes(x = missing)) +
geom_histogram(color = 'black') +
labs(
x = 'Proportion Survey Unanswered',
y = 'Frequency'
)
cog_need <- survey %>%
filter(!is.na(response)) %>%
group_by(subject) %>%
summarize(cog_need_score = mean(response))
## merge cog need with overall data
d <- d %>%
inner_join(cog_need)
## look at it
cor_data <- d %>%
group_by(subject, direction) %>%
summarize(ssd = mean(ssd)) %>%
spread(direction, ssd) %>%
mutate(effect = `Harder than Reference` - `Easier than Reference`) %>%
inner_join(d) %>%
group_by(subject) %>%
summarize(effect = unique(effect), cog_need_score = unique(cog_need_score))
p <- cor_data %>%
ggplot(aes(x = cog_need_score, y = effect)) +
geom_point() +
geom_smooth(method = 'lm') +
labs(
x = 'Need for Cognition',
y = 'Extent Aligned with Prediction'
) +
theme_bw()
ggMarginal(p, type = 'histogram')
cor.test(cor_data$effect, cor_data$cog_need_score)
d$cog_need_score_sc <- scale(d$cog_need_score)[,1]
m1 <- glm(ssd ~ direction * cog_need_score_sc, data = d, family = binomial(link = 'logit'))
print('OVERALL')
summary(m1)
exp(m1$coefficients)
exp(confint(m1))
## follow ups
## high
d$cog_need_score_sc_high <- d$cog_need_score_sc - 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_high, data = d, family = binomial(link = 'logit'))
print('CENTER HIGH')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
## low
d$cog_need_score_sc_low <- d$cog_need_score_sc + 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_low, data = d, family = binomial(link = 'logit'))
print('CENTER LOW')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
test_data <- expand.grid(direction = c('Harder than Reference', 'Easier than Reference'), cog_need_score_sc = c(-1,1))
out <- predict(m1, newdata = test_data, type = 'response', se.fit = TRUE)
test_data$proba <- out$fit
test_data$se <- out$se.fit
test_data %>%
mutate(cog_need_score_sc = as.factor(cog_need_score_sc),
cog_need_score_sc = recode(cog_need_score_sc, `-1` = 'One Standard Deviation Below', `1` = 'One Standard Deviation Above')) %>%
ggplot(aes(x = direction, y = proba, group = cog_need_score_sc)) +
geom_hline(yintercept = .5, linetype = 'dashed', alpha = .6) +
geom_bar(stat = 'identity', aes(fill = cog_need_score_sc), position = position_dodge(width = .9)) +
geom_errorbar(aes(ymin = proba - se, ymax = proba + se), position = position_dodge(width = .9), width = .5) +
ylim(0,1) +
labs(
x = 'Direction',
y = 'Probability Selecting Safe Deck',
fill = 'Need for Cognition'
) +
theme_bw() +
theme(legend.position = 'bottom')
lag <- read.csv('../../../../participation_lag.csv')
avg_lag <- mean(lag$lag_days)
lag %>%
ggplot(aes(x = lag_days)) +
geom_histogram(color = 'black', bins = 20) +
geom_vline(xintercept = avg_lag, linetype = 'dashed')
## join
## losing three Ps from my og data for some reason
d <- d %>%
inner_join(lag, by = c('sona_id' = 'survey_id'))
head(d)
cor_data <- d %>%
group_by(subject) %>%
summarize(cog_need_score = unique(cog_need_score), lag_days = unique(lag_days))
cor_data %>%
ggplot(aes(x = cog_need_score, lag_days)) +
geom_point() +
geom_smooth(method = 'lm')
cor.test(cor_data$cog_need_score, cor_data$lag_days)
library(lme4)
mm1 <- glmer(ssd ~ direction * lag_days_sc * cog_need_score_sc + (1 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
library(tidyverse)
library(ggExtra)
library(plotly)
exp <- str_extract(getwd(), 'exp\\d[a-z]?')
d <- read.csv(paste0(here::here(), '/experiments/analysis/', exp, '/data/', exp, '_main_full.csv'))
demo <- read.csv(paste0(here::here(), '/experiments/analysis/', exp, '/data/', exp, '_demo.csv'))
N <- length(unique(d$subject))
head(d)
reverse_items <- c(3,4,5,7,8,9,12,16,17)
response_code <- data.frame(response = c('neutral', 'somewhat_agree', 'somewhat_disagree', 'strongly_agree', 'strongly_disagree', ''), numeric = c(3, 4, 2, 5, 1, NA))
survey <- demo %>%
gather(question, response, cog_effort_q1:cog_effort_q18) %>%
select(subject, question, response) %>%
inner_join(response_code)
parse_question <- function(q) {
return(as.numeric(sub('.', '', unlist(strsplit(q, split='_'))[3])))
}
survey <- survey %>%
mutate(question = Vectorize(parse_question)(question)) %>%
mutate(numeric_final = ifelse(question %in% reverse_items, 6-numeric, numeric)) %>%
arrange(subject) %>%
select(-response, -numeric) %>%
rename(response = numeric_final)
survey %>%
filter(!is.na(response)) %>%
group_by(subject) %>%
summarize(cog_need = mean(response)) %>%
ggplot(aes(x = cog_need)) +
geom_histogram(color = 'black')
survey %>%
group_by(subject) %>%
summarize(missing = sum(is.na(response)) / nrow(.)) %>%
ggplot(aes(x = missing)) +
geom_histogram(color = 'black') +
labs(
x = 'Proportion Survey Unanswered',
y = 'Frequency'
)
cog_need <- survey %>%
filter(!is.na(response)) %>%
group_by(subject) %>%
summarize(cog_need_score = mean(response))
## merge cog need with overall data
d <- d %>%
inner_join(cog_need)
## look at it
cor_data <- d %>%
group_by(subject, direction) %>%
summarize(ssd = mean(ssd)) %>%
spread(direction, ssd) %>%
mutate(effect = `Harder than Reference` - `Easier than Reference`) %>%
inner_join(d) %>%
group_by(subject) %>%
summarize(effect = unique(effect), cog_need_score = unique(cog_need_score))
p <- cor_data %>%
ggplot(aes(x = cog_need_score, y = effect)) +
geom_point() +
geom_smooth(method = 'lm') +
labs(
x = 'Need for Cognition',
y = 'Extent Aligned with Prediction'
) +
theme_bw()
ggMarginal(p, type = 'histogram')
cor.test(cor_data$effect, cor_data$cog_need_score)
d$cog_need_score_sc <- scale(d$cog_need_score)[,1]
m1 <- glm(ssd ~ direction * cog_need_score_sc, data = d, family = binomial(link = 'logit'))
print('OVERALL')
summary(m1)
exp(m1$coefficients)
exp(confint(m1))
## follow ups
## high
d$cog_need_score_sc_high <- d$cog_need_score_sc - 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_high, data = d, family = binomial(link = 'logit'))
print('CENTER HIGH')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
## low
d$cog_need_score_sc_low <- d$cog_need_score_sc + 1
m_high <- glm(ssd ~ direction * cog_need_score_sc_low, data = d, family = binomial(link = 'logit'))
print('CENTER LOW')
summary(m_high)
exp(m_high$coefficients)
exp(confint(m_high))
test_data <- expand.grid(direction = c('Harder than Reference', 'Easier than Reference'), cog_need_score_sc = c(-1,1))
out <- predict(m1, newdata = test_data, type = 'response', se.fit = TRUE)
test_data$proba <- out$fit
test_data$se <- out$se.fit
test_data %>%
mutate(cog_need_score_sc = as.factor(cog_need_score_sc),
cog_need_score_sc = recode(cog_need_score_sc, `-1` = 'One Standard Deviation Below', `1` = 'One Standard Deviation Above')) %>%
ggplot(aes(x = direction, y = proba, group = cog_need_score_sc)) +
geom_hline(yintercept = .5, linetype = 'dashed', alpha = .6) +
geom_bar(stat = 'identity', aes(fill = cog_need_score_sc), position = position_dodge(width = .9)) +
geom_errorbar(aes(ymin = proba - se, ymax = proba + se), position = position_dodge(width = .9), width = .5) +
ylim(0,1) +
labs(
x = 'Direction',
y = 'Probability Selecting Safe Deck',
fill = 'Need for Cognition'
) +
theme_bw() +
theme(legend.position = 'bottom')
lag <- read.csv('../../../../participation_lag.csv')
avg_lag <- mean(lag$lag_days)
lag %>%
ggplot(aes(x = lag_days)) +
geom_histogram(color = 'black', bins = 20) +
geom_vline(xintercept = avg_lag, linetype = 'dashed')
## join
## losing three Ps from my og data for some reason
d <- d %>%
inner_join(lag, by = c('sona_id' = 'survey_id'))
cor_data <- d %>%
group_by(subject) %>%
summarize(cog_need_score = unique(cog_need_score), lag_days = unique(lag_days))
cor_data %>%
ggplot(aes(x = cog_need_score, lag_days)) +
geom_point() +
geom_smooth(method = 'lm')
cor.test(cor_data$cog_need_score, cor_data$lag_days)
cor_data <- d %>%
group_by(subject, direction) %>%
summarize(ssd = mean(ssd), sona_id = unique(sona_id)) %>%
spread(direction, ssd) %>%
mutate(effect = `Harder than Reference` - `Easier than Reference`) %>%
select(subject, sona_id, effect) %>%
inner_join(lag, by = c('sona_id' = 'survey_id'))
cor_data %>%
ggplot(aes(x = lag_days, y = effect)) +
geom_point() +
geom_smooth(method = 'lm')
cor.test(cor_data$effect, cor_data$lag_days)
d$lag_days_sc  <- scale(d$lag_days)[,1]
d$direction_effect <- ifelse(d$direction=='Easier than Reference', -.5, .5)
m2 <- glm(ssd ~ direction_effect * lag_days_sc, data = d, family = binomial(link = 'logit'))
summary(m2)
exp(m2$coefficients)
exp(confint(m2))
m3 <- glm(ssd ~ direction_effect * lag_days_sc * cog_need_score_sc, data = d, family = binomial(link = 'logit'))
summary(m3)
exp(m3$coefficients)
exp(confint(m3))
library(lme4)
mm1 <- glmer(ssd ~ direction * lag_days_sc * cog_need_score_sc + (1 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
summary(mm1)
summary(mm1)
confint(mm1)
confint(mm1, method = 'wald')
confint(mm1, method = 'Wald')
mm1 <- glmer(ssd ~ direction * cog_need_score_sc + (1 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
mm1 <- glmer(ssd ~ direction * cog_need_score_sc + (1 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
summary(mm1)
confint(mm1, method = 'Wald')
library(lme4)
mm1 <- glmer(ssd ~ direction * cog_need_score_sc + (1 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
mm1a <- glmer(ssd ~ direction * cog_need_score_sc + (1 | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
anova(mm1, mm1a)
#summary(mm1)
#confint(mm1, method = 'Wald')
library(lme4)
mm1 <- glmer(ssd ~ direction * cog_need_score_sc + (1 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
mm1a <- glmer(ssd ~ direction * cog_need_score_sc + (1 | subject) + (0 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
anova(mm1, mm1a)
#summary(mm1)
#confint(mm1, method = 'Wald')
#anova(mm1, mm1a)
summary(mm1a)
confint(mm1a, method = 'Wald')
library(lme4)
#mm1 <- glmer(ssd ~ direction * cog_need_score_sc + (1 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
mm1a <- glmer(ssd ~ direction * cog_need_score_sc + (1 | subject) + (0 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
mm1b <- glmer(ssd ~ direction + cog_need_score_sc + (1 | subject) + (0 + direction | subject), data = d, family = binomial(link = 'logit'), nAGQ = 1)
anova(mm1a, mm1b)
#summary(mm1a)
#confint(mm1a, method = 'Wald')
summary(mm1a)
exp(mm1a$fixef)
exp(fixef(mm1a))
exp(confint(mm1a), method = 'Wald')
summary(mm1a)
exp(fixef(mm1a))
exp(confint(mm1a, method = 'Wald'))
q()
